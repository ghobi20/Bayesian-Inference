---
title: "Estimador de lambda en datos Poisson con a priori Gamma"
author: "Sofia Gamino Estrada"
date: "October 19, 2024"
output: html_document
---
---

En este código se puede dar una densidad de posibles valores para un parámetro lambda desconocido de una distribución Poisson en un intervalo de confianza a partir de un tamaño de muestra n conocido por medio de inferencia Bayesiana

**Input**:
- lambda: Para poder comparar el desempeño del modelo y definir los datos de prueba 
- alpha: Parametro de forma a priori de Gamma
- beta: Parámetro de tasa a priori de Gamma
- p_range: Una secuencia de posibles valores para lambda. Se va a operar sobre esta
- n: El tamaño de la muestra 
**Output**: 
- Distribución a priori
- Distribución a posteriori
- Estimadores a posteriori: MAP, Media, Mediana
- Intervalo de credibilidad de lambda del 95%: Son los posibles valores de lambda
- Distribución de Verosimilitud, así como MV y intervalo de confianza: Para comparación con el método Bayesiano

---

# Descripción del problema
Se desea estimar el parámetro $\lambda$ de una distribución Poisson a partir de una muestra de tamaño $n$. Encuentre la distribución posterior de $\Lambda$ suponiendo que, a priori, $\Lambda\sim \text{Gamma}(\alpha, \beta)$, donde $\alpha$ es parámetro de forma y $\beta$ es parámetro de tasa. Recuerde la función de probabilidad Poisson está dada por:
$$ f_{X|\Lambda}(x|\lambda) = \begin{cases}
\frac{\lambda^x e^{-\lambda}}{x!}, & x=0,1,2,...;\\
0 & \text{otro caso}.
\end{cases}
$$

# Distribución Conjugada

## Hallar los kernel

Primero tenemos que hallar el kernel de $f_{X|\Lambda} (x|\lambda)$ y de $f_{\Lambda}(\lambda)$

### Kernel de $f_{X|\Lambda} (x|\lambda)$

$$f_{X|\Lambda} (x|\lambda) = 
\frac{\lambda^x e^{-\lambda}}{x!}
$$
$$f_{X|\Lambda} (x|\lambda) \propto \lambda^{x}e^{-\lambda}
$$
$$L(\lambda) = \prod^n_{i=1}(f_{X|\Lambda} (x|\lambda)) = \prod^n_{i=1}\lambda^{x}e^{-\lambda}
$$
$$L(\lambda) = \lambda^{s}e^{-\lambda n}, s = \sum^n_{i=1}x_i
$$

### Kernel de $f_{\Lambda}(\lambda)$

$$f_{\Lambda}(\lambda) = \frac{\beta ^ \alpha}{\Gamma(\alpha)} \lambda^{\alpha-1} e^{-\beta\lambda}
$$
$$f_{\Lambda}(\lambda) \propto \lambda^{\alpha-1}e^{-\beta\lambda}
$$

## Distribución Conjugada a posteriori
Ya que tenemos los kernel, podemos sacar la distribución conjugada a posteriori. En este caso, ignoraremos la constante de normalización $\int¹_{0}L(\lambda)f_{\Lambda}(\lambda)d\lambda$ en el denominador.

$$(\lambda|x_1, ..., x_n) = L(\lambda)f_{\Lambda}(\lambda)
$$

$$(\lambda|x_1, ..., x_n) = 
\lambda^{s}e^{-\lambda n}\lambda^{\alpha-1}e^{-\beta\lambda}
$$

$$(\lambda|x_1, ..., x_n) = \lambda^{s\alpha-1}e^{-\lambda n-\beta\lambda}
$$

$$(\lambda|x_1, ..., x_n) = 
\lambda^{\alpha^*-1}e^{-\lambda\beta^*}, \alpha^*=s\alpha,\space b^*=n+\beta
$$

## Estimación de MAP

Podemos hallar MAP de lambda a partir de encontrar cuando la distribución conjugada es 0. Se hace ln(L($\lambda$)), después se deriva $\lambda$ y finalmente igualamos a 0.

$$l(\lambda) = ln[\lambda^{\alpha^*-1}e^{-\lambda\beta^*}]
$$

$$l(\lambda) = ln(\lambda^{\alpha^{*}-1})+ln(e^{-\lambda\beta^*})
$$

$$l(\lambda) = (\alpha^{*}-1)ln(\lambda)-\lambda\beta^*
$$

$$\frac{\partial l(\lambda)}{\partial \lambda} = \frac{\partial}{\partial\lambda}[(\alpha^{*}-1)ln(\lambda)-\lambda\beta^*]
$$

$$ = \frac{\alpha^{*}-1}{\lambda}-\beta^{*}
$$

$$ \frac{\alpha^{*}-1}{\lambda}-\beta^{*} = 0
$$ 

$$\alpha^{*}-1 = \beta^{*}\lambda
$$

$$\lambda^{-}_{MAP} =\frac{\alpha^{*}-1}{\beta^{*}}
$$

# Código de estimador bayesiano

## Creación de datos de prueba
Esto nos va a poder ayudar a comparar nuestro estimador bayesiano con el valor real de $\lambda$ a partir de una distribución Poisson.

```{r}
rm(list = ls())
lambda = 7
n = 30
set.seed(1010)
x = rpois(n, lambda)

```


## A priori Gamma no informativa de lambda

```{r}
alpha =1
beta =1
p_range = seq(0, 10, .01)
priori_l = dgamma(p_range, rate = beta, shape = alpha)
plot(p_range, priori_l, col="magenta", type ="l", lwd = 2, xlab = "lambda", ylab = "f(lambda)", main = "Densidad a priori Gamma para lambda")
```

## A posteriori Gamma de lambda

```{r}
alpha_p = sum(x)*alpha
beta_p = n + beta

post_l = dgamma(p_range, rate = beta_p, shape = alpha_p)

plot(p_range, post_l, col="dodgerblue", type ="l", lwd = 2, xlab = "lambda", ylab = "f(lambda)", main = "Densidad a Posteriori vs a Priori")
lines(p_range, priori_l, col="magenta", type ="l", lwd = 2)

IC_cred = qgamma(c(0.025, 0.975), shape = alpha_p, rate = beta_p)

MAP = (alpha_p-1)/beta_p
Mean = alpha_p/beta_p
Median = qgamma(0.5, shape = alpha_p, rate = beta_p)

abline(v = MAP, lwd = 2, col = "darkmagenta", lty = 4)
abline(v = Mean, lwd = 2, col = "blue4", lty = 4)
abline(v = Median, lwd = 2, col = "green", lty = 4)
abline(v = IC_cred[1], lwd = 2, col = "red", lty = 5)
abline(v = IC_cred[2], lwd = 2, col = "red", lty = 6)
abline(v = lambda, lwd = 2, col = "black", lty = 1)
legend("topright", c("MAP", "Mean", "Median", "IC_cred_lower", "IC_cred_upper", "Real value"), lty = c(4, 4, 4, 5, 6, 1), col = c("darkmagenta", "blue4", "green", "red", "red", "black"))


cat("MAP = ", MAP, "\n")
cat("Mean = ", Mean, "\n")
cat("Median = ", Median, "\n")
cat("Intervalo de credibilidad = ", IC_cred, "\n")
cat("Valor Real = ", lambda, "\n")

```

## Función de Verosimilitud

```{r}

verosim_v = c()
for (l in p_range) {
  verosim = l
  verosim_v = append(verosim_v, verosim)
}

MV = (alpha*n)/sum(x) 

threshold = MV * exp(-qchisq(0.95, df = 1) / 2)

IC_lower = min(p_range[verosim_v >= threshold])
IC_upper = max(p_range[verosim_v >= threshold])

plot(p_range, verosim_v, col="purple", type ="l", lwd = 2, xlab = "lambda", ylab = "L(lambda)", main = "Gráfica de verosimilitud")
abline(v = MV, lwd = 2, col = "gold", lty = 4)
abline(v = IC_lower , lwd = 2, col = "blue4", lty = 4)
abline(v = IC_upper, lwd = 2, col = "blue4", lty = 4)
abline(v = lambda, lwd = 2, col = "black", lty = 1)
legend("topright", c("MV", "Int_conf", "Valor Real"), lty = c(4, 4, 1), col = c("gold", "blue4", "black"))


cat("MV = ", MV, "\n")
cat("Confidence Interval = ", IC_lower, ",", IC_upper)
```