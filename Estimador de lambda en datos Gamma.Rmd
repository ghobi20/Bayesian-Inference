---
title: "Estimador de lamda en datos Gamma con a priori Gamma"
author: "Sofia Gamino Estrada"
date: "October 19, 2024"
output: html_document
---
---

En este código se puede dar una densidad de posibles valores para un parámetro lambda desconocido en un intervalo de confianza a partir de alpha conocido por medio de inferencia Bayesiana

**Input**:
- alpha
- lambda: Para poder comparar el desempeño del modelo y definir los datos de prueba 
- a: Parametro de forma a priori
- b: Parámetro de tasa a priori
- p_range: Una secuencia de posibles valores para lambda. Se va a operar sobre esta

**Output**: 
- Distribución a priori
- Distribución a posteriori
- Estimadores a posteriori: MAP, Media, Mediana
- Intervalo de credibilidad de lambda del 95%: Son los posibles valores de lambda
- Distribución de Verosimilitud, así como MV y intervalo de confianza: Para comparación con el método Bayesiano

---

# Descripción del problema
Sea $X$ una variable aleatoria Gamma de parámetro de forma $\alpha$ conocido y parámetro de tasa $\lambda$ desconocido, con función de densidad
$$ f_{X|\Lambda} (x|\lambda) = \begin{cases}
\frac{ \lambda ^ \alpha}{\Gamma(\alpha)} x^{\alpha-1} e^{-x \lambda}, & x>0;\\
0, & \text{otro caso}.
\end{cases}
$$
Encuentre la distribución posterior de $\Lambda$ suponiendo que se tiene una muestra de tamaño $n$ y que, a priori, $\Lambda$ sigue una distribución Gamma$(a, b)$. Luego, la función de densidad a priori es:
$$ f_{\Lambda}(\lambda) = \begin{cases}
\frac{ b ^ a}{\Gamma(a)} \lambda^{a-1} e^{-b\lambda}, & x>0;\\
0, & \text{otro caso}.
\end{cases}
$$

# Distribución Conjugada

## Hallar los kernel

Primero tenemos que hallar el kernel de $f_{X|\Lambda} (x|\lambda)$ y de $f_{\Lambda}(\lambda)$

### Kernel de $f_{X|\Lambda} (x|\lambda)$

$$f_{X|\Lambda} (x|\lambda) = \frac{1}{\Gamma(\alpha)}\lambda^{\alpha}x^{\alpha-1}e^{-x\lambda}
$$
$$f_{X|\Lambda} (x|\lambda) \propto \lambda^{\alpha}e^{-x\lambda}
$$
$$L(\lambda) = \prod^n_{i=1}(f_{X|\Lambda} (x|\lambda)) = \prod^n_{i=1}\lambda^{\alpha}e^{-x\lambda}
$$
$$L(\lambda) = \lambda^{n\alpha}e^{-s\lambda}, s = \sum^n_{i=1}x_i
$$

### Kernel de $f_{\Lambda}(\lambda)$

$$f_{\Lambda}(\lambda) = \frac{ b ^ a}{\Gamma(a)} \lambda^{a-1} e^{-b\lambda}
$$
$$f_{\Lambda}(\lambda) \propto \lambda^{a-1}e^{-b\lambda}
$$

## Distribución Conjugada a posteriori
Ya que tenemos los kernel, podemos sacar la distribución conjugada a posteriori. En este caso, ignoraremos la constante de normalización $\int¹_{0}L(\lambda)f_{\Lambda}(\lambda)d\lambda$ en el denominador.

$$(\lambda|x_1, ..., x_n) = L(\lambda)f_{\Lambda}(\lambda)
$$

$$(\lambda|x_1, ..., x_n) = \lambda^{n\alpha}e^{-s\lambda}\lambda^{a-1}e^{-b\lambda}
$$

$$(\lambda|x_1, ..., x_n) = \lambda^{n\alpha+a-1}e^{-s\lambda-b\lambda}
$$

$$(\lambda|x_1, ..., x_n) = \lambda^{a^*-1}e^{-b^*\lambda}, a^*=n\alpha+a,\space b^*=s+b
$$

## Estimación de MAP

Podemos hallar MAP de lambda a partir de encontrar cuando la distribución conjugada es 0. Se hace ln(L($\lambda$)), después se deriva $\lambda$ y finalmente igualamos a 0.

$$l(\lambda) = ln[\lambda^{a^*-1}e^{-b^*\lambda}]
$$

$$l(\lambda) = ln(\lambda^{a^{*}-1})+ln(e^{-b^{*}\lambda})
$$

$$l(\lambda) = a^{*}-1ln(\lambda)-b^{*}\lambda
$$

$$\frac{\partial l(\lambda)}{\partial \lambda} = \frac{\partial}{\partial\lambda}[a^{*}-1ln(\lambda)-b^{*}\lambda]
$$

$$ = \frac{a^{*}-1}{\lambda}-b^{*}
$$

$$ \frac{a^{*}-1}{\lambda}-b^{*} = 0
$$ 

$$a^{*}-1 = b^{*}\lambda
$$

$$\lambda^{-}_{MAP} =\frac{a^{*}-1}{b^{*}}
$$

# Código de estimador bayesiano

## Creación de datos de prueba
Esto nos va a poder ayudar a comparar nuestro estimador bayesiano con el valor real de $\lambda$ a partir de una distribución Gamma.

```{r}
rm(list = ls())
alpha = 2
lambda = 5
n = 30
set.seed(1010)
x = rgamma(n, rate = lambda, shape = alpha)

```


## A priori Gamma no informativa de lambda

```{r}
a =10
b =1/10
p_range = seq(0, 15, .01)
priori_l = dgamma(p_range, rate = b, shape = a)
plot(p_range, priori_l, col="magenta", type ="l", lwd = 2, xlab = "lambda", ylab = "f(lambda)", main = "Densidad a priori Gamma para lambda")
```

## A posteriori Gamma de lambda

```{r}
a_p = n*alpha + a
b_p = sum(x) + b

post_l = dgamma(p_range, rate = b_p, shape = a_p)

plot(p_range, post_l, col="dodgerblue", type ="l", lwd = 2, xlab = "lambda", ylab = "f(lambda)", main = "Densidad a Posteriori vs a Priori")
lines(p_range, priori_l, col="magenta", type ="l", lwd = 2)

IC_cred = qgamma(c(0.025, 0.975), shape = a_p, rate = b_p)

MAP = (a_p-1)/b_p
Mean = a_p/b_p
Median = qgamma(0.5, shape = a_p, rate = b_p)

abline(v = MAP, lwd = 2, col = "darkmagenta", lty = 4)
abline(v = Mean, lwd = 2, col = "blue4", lty = 4)
abline(v = Median, lwd = 2, col = "green", lty = 4)
abline(v = IC_cred[1], lwd = 2, col = "red", lty = 5)
abline(v = IC_cred[2], lwd = 2, col = "red", lty = 6)
abline(v = lambda, lwd = 2, col = "black", lty = 1)
legend("topright", c("MAP", "Mean", "Median", "IC_cred_lower", "IC_cred_upper", "Real value"), lty = c(4, 4, 4, 5, 6, 1), col = c("darkmagenta", "blue4", "green", "red", "red", "black"))


cat("MAP = ", MAP, "\n")
cat("Mean = ", Mean, "\n")
cat("Median = ", Median, "\n")
cat("Intervalo de credibilidad = ", IC_cred, "\n")
cat("Valor Real = ", lambda, "\n")

```

## Función de Verosimilitud

```{r}

verosim_v = c()
for (l in p_range) {
  verosim = (l^{n*alpha})*(exp(-sum(x)*l))
  verosim_v = append(verosim_v, verosim)
}

MV = (alpha*n)/sum(x)

threshold = MV * exp(-qchisq(0.95, df = 1) / 2)

IC_lower = min(p_range[verosim_v >= threshold])
IC_upper = max(p_range[verosim_v >= threshold])

plot(p_range, verosim_v, col="purple", type ="l", lwd = 2, xlab = "lambda", ylab = "L(lambda)", main = "Gráfica de verosimilitud")
abline(v = MV, lwd = 2, col = "gold", lty = 4)
abline(v = IC_lower , lwd = 2, col = "blue4", lty = 4)
abline(v = IC_upper, lwd = 2, col = "blue4", lty = 4)
abline(v = lambda, lwd = 2, col = "black", lty = 1)
legend("topright", c("MV", "Int_conf", "Valor Real"), lty = c(4, 4, 1), col = c("gold", "blue4", "black"))


cat("MV = ", MV, "\n")
cat("Confidence Interval = ", IC_lower, ",", IC_upper)
```

